"""
æµ‹è¯• Gemini API é›†æˆ
"""

import asyncio
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from core.ai_engine import AIEngine, TaskComplexity, AIConfig
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


async def test_gemini_simple():
    """æµ‹è¯•Geminiç®€å•ä»»åŠ¡"""
    print("=" * 60)
    print("æµ‹è¯• 1: Geminiç®€å•æ–‡æœ¬ç”Ÿæˆ")
    print("=" * 60)
    
    # åˆ›å»ºAIå¼•æ“ï¼ˆä¼šè‡ªåŠ¨ä»ç¯å¢ƒå˜é‡åŠ è½½GEMINI_API_KEYï¼‰
    engine = AIEngine()
    
    if not engine.gemini_model:
        print("âš ï¸ Geminiæœªé…ç½®ï¼Œè·³è¿‡æµ‹è¯•")
        print("è¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®GEMINI_API_KEY")
        return False
    
    prompt = "ç”¨ä¸€å¥è¯ä»‹ç»äººå·¥æ™ºèƒ½ã€‚"
    
    response = await engine._call_gemini(
        prompt=prompt,
        temperature=0.7
    )
    
    if response.success:
        print(f"âœ… æµ‹è¯•é€šè¿‡")
        print(f"   - æä¾›å•†: {response.provider}")
        print(f"   - æ¨¡å‹: {response.model}")
        print(f"   - è€—æ—¶: {response.latency:.2f}s")
        print(f"   - å“åº”: {response.content[:100]}...")
        return True
    else:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {response.error}")
        return False


async def test_smart_scheduling():
    """æµ‹è¯•æ™ºèƒ½è°ƒåº¦"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 2: æ™ºèƒ½è°ƒåº¦ç®—æ³•")
    print("=" * 60)
    
    engine = AIEngine()
    
    # æµ‹è¯•ä¸åŒå¤æ‚åº¦çš„ä»»åŠ¡
    test_cases = [
        (TaskComplexity.SIMPLE, "ä¼˜åŒ–è¿™ä¸ªæ ‡é¢˜ï¼šiPhone 15"),
        (TaskComplexity.MEDIUM, "ä¸ºä¸€æ¬¾æ™ºèƒ½æ‰‹è¡¨å†™ä¸€æ®µäº§å“æè¿°"),
        (TaskComplexity.COMPLEX, "å†™ä¸€ç¯‡å…³äºAIå‘å±•è¶‹åŠ¿çš„åˆ†ææ–‡ç« "),
    ]
    
    results = []
    
    for complexity, prompt in test_cases:
        print(f"\nğŸ¯ æµ‹è¯• {complexity.name} ä»»åŠ¡")
        print(f"   æç¤ºè¯: {prompt}")
        
        response = await engine.generate(
            prompt=prompt,
            complexity=complexity,
            temperature=0.7
        )
        
        if response.success:
            print(f"âœ… æˆåŠŸ - ä½¿ç”¨: {response.provider}")
            print(f"   è€—æ—¶: {response.latency:.2f}s")
            print(f"   å“åº”: {response.content[:80]}...")
            results.append(True)
        else:
            print(f"âŒ å¤±è´¥: {response.error}")
            results.append(False)
    
    success_rate = sum(results) / len(results) * 100
    print(f"\nğŸ“Š æµ‹è¯•ç»“æœ: {sum(results)}/{len(results)} é€šè¿‡ ({success_rate:.0f}%)")
    
    return all(results)


async def test_fallback():
    """æµ‹è¯•é™çº§ç­–ç•¥"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 3: é™çº§ç­–ç•¥")
    print("=" * 60)
    
    # æµ‹è¯•å½“Ollamaå¤±è´¥æ—¶ï¼Œæ˜¯å¦ä¼šé™çº§åˆ°Gemini
    config = AIConfig(
        ollama_url="http://localhost:99999",  # é”™è¯¯çš„åœ°å€ï¼Œä¼šå¤±è´¥
        fallback_enabled=True
    )
    
    engine = AIEngine(config)
    
    if not engine.gemini_model:
        print("âš ï¸ Geminiæœªé…ç½®ï¼Œæ— æ³•æµ‹è¯•é™çº§")
        return False
    
    prompt = "è¯´ä¸€å¥Hello"
    
    response = await engine.generate(
        prompt=prompt,
        complexity=TaskComplexity.MEDIUM,
        temperature=0.7
    )
    
    if response.success and response.provider == "gemini":
        print(f"âœ… é™çº§æˆåŠŸ - ä»Ollamaé™çº§åˆ°Gemini")
        print(f"   å“åº”: {response.content}")
        return True
    else:
        print(f"âŒ é™çº§å¤±è´¥")
        return False


async def test_statistics():
    """æµ‹è¯•ç»Ÿè®¡åŠŸèƒ½"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 4: ç»Ÿè®¡åŠŸèƒ½")
    print("=" * 60)
    
    engine = AIEngine()
    
    # è¿›è¡Œå‡ æ¬¡è°ƒç”¨
    prompts = [
        "Hello",
        "ä½ å¥½",
        "Bonjour"
    ]
    
    for prompt in prompts:
        await engine.generate(prompt, complexity=TaskComplexity.SIMPLE)
    
    # è·å–ç»Ÿè®¡
    stats = engine.get_statistics()
    
    print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    for provider, data in stats.items():
        if data['total_calls'] > 0:
            print(f"\n{provider.upper()}:")
            print(f"  - æ€»è°ƒç”¨: {data['total_calls']}")
            print(f"  - æˆåŠŸ: {data['success_calls']}")
            print(f"  - å¤±è´¥: {data['failed_calls']}")
            print(f"  - å¹³å‡å»¶è¿Ÿ: {data['avg_latency']:.2f}s")
    
    return True


async def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸš€ å¼€å§‹æµ‹è¯• Gemini API é›†æˆ")
    print()
    
    tests = [
        test_gemini_simple,
        test_smart_scheduling,
        test_fallback,
        test_statistics,
    ]
    
    results = []
    for test in tests:
        try:
            result = await test()
            results.append(result)
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¼‚å¸¸: {e}")
            results.append(False)
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•æ€»ç»“")
    print("=" * 60)
    
    total = len(results)
    passed = sum(1 for r in results if r)
    
    print(f"æ€»æµ‹è¯•æ•°: {total}")
    print(f"é€šè¿‡: {passed}")
    print(f"å¤±è´¥: {total - passed}")
    print(f"é€šè¿‡ç‡: {passed/total*100:.0f}%")
    
    if passed == total:
        print("\nâœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    else:
        print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥")
    
    print("\n" + "=" * 60)


if __name__ == "__main__":
    asyncio.run(main())

