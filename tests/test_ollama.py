"""
æµ‹è¯• Ollama è¿æ¥å’Œ AI å¼•æ“
Day 1 æµ‹è¯•è„šæœ¬
"""

import asyncio
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from core.ai_engine import AIEngine, AIConfig, TaskComplexity


async def test_connection():
    """æµ‹è¯•1: Ollamaè¿æ¥æµ‹è¯•"""
    print("\n" + "="*60)
    print("ğŸ§ª æµ‹è¯•1: Ollamaè¿æ¥æµ‹è¯•")
    print("="*60)
    
    config = AIConfig(
        ollama_url="http://localhost:11434",
        ollama_model="deepseek-r1:1.5b"
    )
    
    engine = AIEngine(config)
    success = await engine.test_ollama_connection()
    
    if success:
        print("\nâœ… è¿æ¥æµ‹è¯•é€šè¿‡ï¼")
        return True
    else:
        print("\nâŒ è¿æ¥æµ‹è¯•å¤±è´¥ï¼")
        print("\nè¯·æ£€æŸ¥ï¼š")
        print("  1. Ollama æ˜¯å¦å·²å¯åŠ¨ï¼Ÿï¼ˆè¿è¡Œ 'ollama serve'ï¼‰")
        print("  2. æ¨¡å‹æ˜¯å¦å·²ä¸‹è½½ï¼Ÿï¼ˆè¿è¡Œ 'ollama pull deepseek-r1:1.5b'ï¼‰")
        return False


async def test_simple_generation():
    """æµ‹è¯•2: ç®€å•æ–‡æœ¬ç”Ÿæˆ"""
    print("\n" + "="*60)
    print("ğŸ§ª æµ‹è¯•2: ç®€å•æ–‡æœ¬ç”Ÿæˆ")
    print("="*60)
    
    engine = AIEngine()
    
    prompt = "ç”¨ä¸€å¥è¯ä»‹ç»ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ã€‚"
    
    print(f"\nğŸ“ æç¤ºè¯: {prompt}")
    print("â³ ç”Ÿæˆä¸­...")
    
    response = await engine.generate(
        prompt=prompt,
        complexity=TaskComplexity.SIMPLE,
        temperature=0.7
    )
    
    if response.success:
        print(f"\nâœ… ç”ŸæˆæˆåŠŸï¼")
        print(f"â±ï¸  è€—æ—¶: {response.latency:.2f}ç§’")
        print(f"ğŸ“Š Tokens: {response.tokens}")
        print(f"\nğŸ’¬ å›å¤:\n{response.content}")
        return True
    else:
        print(f"\nâŒ ç”Ÿæˆå¤±è´¥: {response.error}")
        return False


async def test_title_optimization():
    """æµ‹è¯•3: é—²é±¼æ ‡é¢˜ä¼˜åŒ–ï¼ˆå®é™…åº”ç”¨åœºæ™¯ï¼‰"""
    print("\n" + "="*60)
    print("ğŸ§ª æµ‹è¯•3: é—²é±¼æ ‡é¢˜ä¼˜åŒ–")
    print("="*60)
    
    engine = AIEngine()
    
    original_title = "ä¹æˆæ–°iPhone 13 128G"
    
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç”µå•†æ ‡é¢˜ä¼˜åŒ–åŠ©æ‰‹ã€‚
ä¼˜åŒ–è¦æ±‚ï¼š
1. ä¿ç•™å…³é”®ä¿¡æ¯ï¼ˆå“ç‰Œã€å‹å·ã€å®¹é‡ã€æˆè‰²ï¼‰
2. æ·»åŠ å¸å¼•äººçš„å½¢å®¹è¯
3. æ§åˆ¶åœ¨30å­—ä»¥å†…
4. åªè¿”å›ä¼˜åŒ–åçš„æ ‡é¢˜ï¼Œä¸è¦è§£é‡Š"""
    
    prompt = f"è¯·ä¼˜åŒ–è¿™ä¸ªé—²é±¼æ ‡é¢˜ï¼š{original_title}"
    
    print(f"\nğŸ“ åŸæ ‡é¢˜: {original_title}")
    print("â³ ä¼˜åŒ–ä¸­...")
    
    response = await engine.generate(
        prompt=prompt,
        system_prompt=system_prompt,
        complexity=TaskComplexity.SIMPLE,
        temperature=0.8
    )
    
    if response.success:
        print(f"\nâœ… ä¼˜åŒ–æˆåŠŸï¼")
        print(f"â±ï¸  è€—æ—¶: {response.latency:.2f}ç§’")
        print(f"\nâœ¨ ä¼˜åŒ–åæ ‡é¢˜:\n{response.content}")
        return True
    else:
        print(f"\nâŒ ä¼˜åŒ–å¤±è´¥: {response.error}")
        return False


async def test_batch_processing():
    """æµ‹è¯•4: æ‰¹é‡å¤„ç†æµ‹è¯•"""
    print("\n" + "="*60)
    print("ğŸ§ª æµ‹è¯•4: æ‰¹é‡å¤„ç†æµ‹è¯•")
    print("="*60)
    
    engine = AIEngine()
    
    titles = [
        "MacBook Pro 2020æ¬¾",
        "å°ç±³æ‰‹ç¯7",
        "ç´¢å°¼é™å™ªè€³æœº"
    ]
    
    system_prompt = """ä½ æ˜¯ç”µå•†æ ‡é¢˜ä¼˜åŒ–åŠ©æ‰‹ã€‚è¦æ±‚ï¼š
1. æ·»åŠ å¸å¼•çœ¼çƒçš„è¯æ±‡
2. ä¿æŒç®€æ´
3. åªè¿”å›æ ‡é¢˜"""
    
    print(f"\nğŸ“‹ å¾…ä¼˜åŒ–æ ‡é¢˜æ•°é‡: {len(titles)}")
    
    results = []
    for i, title in enumerate(titles, 1):
        print(f"\n[{i}/{len(titles)}] å¤„ç†: {title}")
        
        response = await engine.generate(
            prompt=f"ä¼˜åŒ–æ ‡é¢˜ï¼š{title}",
            system_prompt=system_prompt,
            complexity=TaskComplexity.SIMPLE
        )
        
        if response.success:
            print(f"  âœ“ æˆåŠŸ ({response.latency:.2f}s)")
            results.append({
                'original': title,
                'optimized': response.content.strip(),
                'latency': response.latency
            })
        else:
            print(f"  âœ— å¤±è´¥: {response.error}")
    
    # æ˜¾ç¤ºç»“æœ
    print("\n" + "-"*60)
    print("ğŸ“Š æ‰¹é‡å¤„ç†ç»“æœ:")
    print("-"*60)
    for i, result in enumerate(results, 1):
        print(f"\n{i}. åŸæ ‡é¢˜: {result['original']}")
        print(f"   ä¼˜åŒ–å: {result['optimized']}")
        print(f"   è€—æ—¶: {result['latency']:.2f}s")
    
    # ç»Ÿè®¡
    if results:
        avg_latency = sum(r['latency'] for r in results) / len(results)
        print(f"\nâœ… æˆåŠŸ: {len(results)}/{len(titles)}")
        print(f"â±ï¸  å¹³å‡è€—æ—¶: {avg_latency:.2f}ç§’")
        return True
    else:
        print("\nâŒ å…¨éƒ¨å¤±è´¥")
        return False


async def test_stats():
    """æµ‹è¯•5: ç»Ÿè®¡ä¿¡æ¯æ˜¾ç¤º"""
    print("\n" + "="*60)
    print("ğŸ§ª æµ‹è¯•5: æŸ¥çœ‹å¼•æ“ç»Ÿè®¡")
    print("="*60)
    
    engine = AIEngine()
    
    # è¿›è¡Œå‡ æ¬¡è°ƒç”¨
    for i in range(3):
        await engine.generate(
            prompt=f"æµ‹è¯•æ¶ˆæ¯ {i+1}",
            complexity=TaskComplexity.SIMPLE
        )
    
    # æ˜¾ç¤ºç»Ÿè®¡
    engine.print_stats()
    return True


async def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n")
    print("="*60)
    print("ğŸš€ JieDimension Toolkit - AIå¼•æ“æµ‹è¯•å¥—ä»¶")
    print("="*60)
    print("ğŸ“… Day 1: Ollamaè¿æ¥ä¸åŸºç¡€åŠŸèƒ½æµ‹è¯•")
    print(f"ğŸ¤– æ¨¡å‹: deepseek-r1:1.5b")
    print("="*60)
    
    tests = [
        ("è¿æ¥æµ‹è¯•", test_connection),
        ("ç®€å•ç”Ÿæˆ", test_simple_generation),
        ("æ ‡é¢˜ä¼˜åŒ–", test_title_optimization),
        ("æ‰¹é‡å¤„ç†", test_batch_processing),
        ("ç»Ÿè®¡ä¿¡æ¯", test_stats),
    ]
    
    results = []
    
    for test_name, test_func in tests:
        try:
            success = await test_func()
            results.append((test_name, success))
        except Exception as e:
            print(f"\nâŒ æµ‹è¯•å¼‚å¸¸: {e}")
            results.append((test_name, False))
        
        # æµ‹è¯•é—´éš”
        await asyncio.sleep(0.5)
    
    # æœ€ç»ˆæŠ¥å‘Š
    print("\n" + "="*60)
    print("ğŸ“‹ æµ‹è¯•æŠ¥å‘Š")
    print("="*60)
    
    passed = sum(1 for _, success in results if success)
    total = len(results)
    
    for test_name, success in results:
        status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
        print(f"{status} - {test_name}")
    
    print("-"*60)
    print(f"æ€»è®¡: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼AIå¼•æ“å·¥ä½œæ­£å¸¸ï¼")
    else:
        print(f"\nâš ï¸ æœ‰ {total - passed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥")
    
    print("="*60 + "\n")


if __name__ == "__main__":
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    asyncio.run(run_all_tests())

