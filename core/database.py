"""
JieDimension Toolkit - æ•°æ®åº“ç®¡ç†å™¨
æ”¯æŒå•†å“ã€ä»»åŠ¡ã€AIä½¿ç”¨ç»Ÿè®¡ç­‰æ•°æ®ç®¡ç†
Version: 1.17.1
"""

import aiosqlite
import json
import os
import sys
from typing import List, Dict, Any, Optional
from datetime import datetime
from pathlib import Path
import logging

logger = logging.getLogger(__name__)


def get_base_path():
    """è·å–ç¨‹åºåŸºç¡€è·¯å¾„"""
    if getattr(sys, 'frozen', False):
        return Path(sys.executable).parent
    else:
        return Path(__file__).parent.parent


def get_resource_path(relative_path):
    """è·å–èµ„æºæ–‡ä»¶è·¯å¾„"""
    if getattr(sys, 'frozen', False):
        return Path(sys._MEIPASS) / relative_path
    else:
        return Path(__file__).parent.parent / relative_path


class Database:
    """æ•°æ®åº“ç®¡ç†å™¨"""
    
    def __init__(self, db_path: str = None):
        """
        åˆå§‹åŒ–æ•°æ®åº“ç®¡ç†å™¨
        
        Args:
            db_path: æ•°æ®åº“æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨BASE_DIR/data/database.dbï¼‰
        """
        # å¦‚æœæœªæä¾›è·¯å¾„ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„
        if db_path is None:
            base_path = get_base_path()
            db_path = str(base_path / "data" / "database.db")
        
        # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œè½¬æ¢ä¸ºç»å¯¹è·¯å¾„
        if not os.path.isabs(db_path):
            base_path = get_base_path()
            db_path = str(base_path / db_path)
        
        self.db_path = db_path
        self.conn: Optional[aiosqlite.Connection] = None
        
        # ç¡®ä¿dataç›®å½•å­˜åœ¨
        db_dir = os.path.dirname(self.db_path)
        if db_dir:
            os.makedirs(db_dir, exist_ok=True)
    
    async def connect(self):
        """è¿æ¥æ•°æ®åº“"""
        try:
            self.conn = await aiosqlite.connect(self.db_path)
            self.conn.row_factory = aiosqlite.Row  # è¿”å›å­—å…¸å½¢å¼çš„è¡Œ
            await self.conn.execute("PRAGMA foreign_keys = ON")
            await self._init_tables()
            logger.info(f"âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ: {self.db_path}")
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            raise
    
    async def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.conn:
            await self.conn.close()
            logger.info("æ•°æ®åº“è¿æ¥å·²å…³é—­")
    
    async def _init_tables(self):
        """åˆå§‹åŒ–è¡¨ç»“æ„"""
        try:
            # ä¼˜å…ˆä»èµ„æºç›®å½•æŸ¥æ‰¾schemaæ–‡ä»¶ï¼ˆæ‰“åŒ…åï¼‰
            schema_path = get_resource_path("data/schema.sql")
            
            # å¦‚æœä¸å­˜åœ¨ï¼Œå°è¯•ä»åŸºç¡€ç›®å½•æŸ¥æ‰¾
            if not schema_path.exists():
                schema_path = get_base_path() / "data" / "schema.sql"
            
            if not schema_path.exists():
                logger.warning(f"âš ï¸ Schemaæ–‡ä»¶ä¸å­˜åœ¨: {schema_path}")
                logger.info("å°†ä½¿ç”¨å†…ç½®çš„é»˜è®¤è¡¨ç»“æ„")
                # è¿™é‡Œå¯ä»¥æ·»åŠ é»˜è®¤çš„è¡¨ç»“æ„SQL
                return
            
            # è¯»å–å¹¶æ‰§è¡Œschema
            with open(schema_path, "r", encoding="utf-8") as f:
                sql = f.read()
            
            await self.conn.executescript(sql)
            await self.conn.commit()
            
            logger.info(f"âœ… æ•°æ®åº“è¡¨åˆå§‹åŒ–å®Œæˆ: {schema_path}")
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    # ===== å•†å“ç›¸å…³æ“ä½œ =====
    
    async def insert_products(self, products: List[Dict[str, Any]]) -> int:
        """
        æ‰¹é‡æ’å…¥å•†å“
        
        Args:
            products: å•†å“åˆ—è¡¨
            
        Returns:
            æ’å…¥çš„å•†å“æ•°é‡
        """
        if not products:
            return 0
        
        sql = """
        INSERT INTO products (
            title, title_original, price, category, 
            description, images, quantity, status,
            platform, import_time, row_number
        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """
        
        data = []
        for p in products:
            data.append((
                p.get("title", ""),
                p.get("title_original", p.get("title", "")),
                p.get("price", 0),
                p.get("category", ""),
                p.get("description", ""),
                json.dumps(p.get("images", []), ensure_ascii=False),
                p.get("quantity", 1),
                p.get("status", "å¾…å‘å¸ƒ"),
                p.get("platform", "xianyu"),
                p.get("import_time", datetime.now().isoformat()),
                p.get("row_number", 0)
            ))
        
        try:
            cursor = await self.conn.executemany(sql, data)
            await self.conn.commit()
            
            count = cursor.rowcount
            logger.info(f"âœ… æˆåŠŸæ’å…¥ {count} ä¸ªå•†å“")
            return count
        except Exception as e:
            logger.error(f"âŒ æ’å…¥å•†å“å¤±è´¥: {e}")
            raise
    
    async def get_products(
        self,
        status: Optional[str] = None,
        platform: Optional[str] = None,
        limit: int = 100,
        offset: int = 0
    ) -> List[Dict[str, Any]]:
        """
        è·å–å•†å“åˆ—è¡¨
        
        Args:
            status: çŠ¶æ€è¿‡æ»¤
            platform: å¹³å°è¿‡æ»¤
            limit: è¿”å›æ•°é‡é™åˆ¶
            offset: åç§»é‡
            
        Returns:
            å•†å“åˆ—è¡¨
        """
        sql = "SELECT * FROM products WHERE 1=1"
        params = []
        
        if status:
            sql += " AND status = ?"
            params.append(status)
        
        if platform:
            sql += " AND platform = ?"
            params.append(platform)
        
        sql += " ORDER BY created_at DESC LIMIT ? OFFSET ?"
        params.extend([limit, offset])
        
        try:
            cursor = await self.conn.execute(sql, params)
            rows = await cursor.fetchall()
            
            # è½¬æ¢ä¸ºå­—å…¸å¹¶è§£æJSONå­—æ®µ
            products = []
            for row in rows:
                product = dict(row)
                # è§£æimages JSON
                if product.get("images"):
                    try:
                        product["images"] = json.loads(product["images"])
                    except:
                        product["images"] = []
                products.append(product)
            
            return products
        except Exception as e:
            logger.error(f"âŒ æŸ¥è¯¢å•†å“å¤±è´¥: {e}")
            return []
    
    async def update_product_status(
        self,
        product_id: int,
        status: str,
        published_id: Optional[str] = None,
        published_url: Optional[str] = None
    ):
        """
        æ›´æ–°å•†å“çŠ¶æ€
        
        Args:
            product_id: å•†å“ID
            status: æ–°çŠ¶æ€
            published_id: å¹³å°å•†å“ID
            published_url: å•†å“é“¾æ¥
        """
        sql = """
        UPDATE products 
        SET status = ?, 
            published_id = ?,
            published_url = ?,
            published_at = ?,
            updated_at = CURRENT_TIMESTAMP
        WHERE id = ?
        """
        
        published_at = datetime.now().isoformat() if status == "å·²å‘å¸ƒ" else None
        
        try:
            await self.conn.execute(sql, (
                status,
                published_id,
                published_url,
                published_at,
                product_id
            ))
            await self.conn.commit()
            logger.info(f"âœ… æ›´æ–°å•†å“çŠ¶æ€: ID={product_id}, status={status}")
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°å•†å“çŠ¶æ€å¤±è´¥: {e}")
            raise
    
    async def delete_product(self, product_id: int):
        """
        åˆ é™¤å•†å“
        
        Args:
            product_id: å•†å“ID
        """
        sql = "DELETE FROM products WHERE id = ?"
        
        try:
            await self.conn.execute(sql, (product_id,))
            await self.conn.commit()
            logger.info(f"âœ… åˆ é™¤å•†å“: ID={product_id}")
        except Exception as e:
            logger.error(f"âŒ åˆ é™¤å•†å“å¤±è´¥: {e}")
            raise
    
    async def count_products(self, platform: Optional[str] = None) -> int:
        """
        ç»Ÿè®¡å•†å“æ•°é‡
        
        Args:
            platform: å¹³å°åç§°ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            int: å•†å“æ•°é‡
        """
        if platform:
            sql = "SELECT COUNT(*) FROM products WHERE platform = ?"
            cursor = await self.conn.execute(sql, (platform,))
        else:
            sql = "SELECT COUNT(*) FROM products"
            cursor = await self.conn.execute(sql)
        
        result = await cursor.fetchone()
        return result[0] if result else 0
    
    # ===== ä»»åŠ¡ç›¸å…³æ“ä½œ =====
    
    async def create_task(
        self,
        task_type: str,
        name: Optional[str] = None,
        data: Optional[Dict] = None
    ) -> int:
        """
        åˆ›å»ºä»»åŠ¡
        
        Args:
            task_type: ä»»åŠ¡ç±»å‹
            name: ä»»åŠ¡åç§°
            data: ä»»åŠ¡æ•°æ®
            
        Returns:
            ä»»åŠ¡ID
        """
        sql = """
        INSERT INTO tasks (type, name, data, status)
        VALUES (?, ?, ?, 'pending')
        """
        
        try:
            cursor = await self.conn.execute(sql, (
                task_type,
                name,
                json.dumps(data, ensure_ascii=False) if data else None
            ))
            await self.conn.commit()
            
            task_id = cursor.lastrowid
            logger.info(f"âœ… åˆ›å»ºä»»åŠ¡: ID={task_id}, type={task_type}")
            return task_id
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºä»»åŠ¡å¤±è´¥: {e}")
            raise
    
    async def update_task_progress(
        self,
        task_id: int,
        progress: float,
        status: Optional[str] = None
    ):
        """
        æ›´æ–°ä»»åŠ¡è¿›åº¦
        
        Args:
            task_id: ä»»åŠ¡ID
            progress: è¿›åº¦ (0-100)
            status: çŠ¶æ€
        """
        sql = "UPDATE tasks SET progress = ?"
        params = [progress]
        
        if status:
            sql += ", status = ?"
            params.append(status)
        
        sql += " WHERE id = ?"
        params.append(task_id)
        
        try:
            await self.conn.execute(sql, params)
            await self.conn.commit()
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°ä»»åŠ¡è¿›åº¦å¤±è´¥: {e}")
    
    async def complete_task(
        self,
        task_id: int,
        result: Optional[Dict] = None,
        error: Optional[str] = None
    ):
        """
        å®Œæˆä»»åŠ¡
        
        Args:
            task_id: ä»»åŠ¡ID
            result: ä»»åŠ¡ç»“æœ
            error: é”™è¯¯ä¿¡æ¯
        """
        status = "failed" if error else "completed"
        
        sql = """
        UPDATE tasks 
        SET status = ?,
            progress = 100,
            result = ?,
            error = ?,
            completed_at = CURRENT_TIMESTAMP
        WHERE id = ?
        """
        
        try:
            await self.conn.execute(sql, (
                status,
                json.dumps(result, ensure_ascii=False) if result else None,
                error,
                task_id
            ))
            await self.conn.commit()
            logger.info(f"âœ… ä»»åŠ¡å®Œæˆ: ID={task_id}, status={status}")
        except Exception as e:
            logger.error(f"âŒ å®Œæˆä»»åŠ¡å¤±è´¥: {e}")
    
    async def get_tasks_by_date_range(
        self,
        start_time: str,
        end_time: str,
        status: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """
        è·å–æŒ‡å®šæ—¶é—´èŒƒå›´å†…çš„ä»»åŠ¡
        
        Args:
            start_time: å¼€å§‹æ—¶é—´ï¼ˆISOæ ¼å¼ï¼‰
            end_time: ç»“æŸæ—¶é—´ï¼ˆISOæ ¼å¼ï¼‰
            status: ä»»åŠ¡çŠ¶æ€ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            ä»»åŠ¡åˆ—è¡¨
        """
        if status:
            sql = """
            SELECT * FROM tasks 
            WHERE created_at >= ? AND created_at <= ? AND status = ?
            ORDER BY created_at DESC
            """
            cursor = await self.conn.execute(sql, (start_time, end_time, status))
        else:
            sql = """
            SELECT * FROM tasks 
            WHERE created_at >= ? AND created_at <= ?
            ORDER BY created_at DESC
            """
            cursor = await self.conn.execute(sql, (start_time, end_time))
        
        rows = await cursor.fetchall()
        
        tasks = []
        for row in rows:
            task = dict(row)
            # è§£æJSONå­—æ®µ
            if task.get('data'):
                task['data'] = json.loads(task['data'])
            if task.get('result'):
                task['result'] = json.loads(task['result'])
            tasks.append(task)
        
        return tasks
    
    async def get_tasks(
        self,
        type: Optional[str] = None,
        status: Optional[str] = None,
        platform: Optional[str] = None,
        start_date: Optional[str] = None,
        limit: int = 100
    ) -> List[Dict[str, Any]]:
        """
        è·å–ä»»åŠ¡åˆ—è¡¨ï¼ˆæ”¯æŒå¤šæ¡ä»¶ç­›é€‰ï¼‰
        
        Args:
            type: ä»»åŠ¡ç±»å‹ç­›é€‰
            status: çŠ¶æ€ç­›é€‰
            platform: å¹³å°ç­›é€‰
            start_date: å¼€å§‹æ—¥æœŸï¼ˆISOæ ¼å¼ï¼‰
            limit: è¿”å›æ•°é‡é™åˆ¶
            
        Returns:
            ä»»åŠ¡åˆ—è¡¨
        """
        sql = "SELECT * FROM tasks WHERE 1=1"
        params = []
        
        if type:
            sql += " AND type = ?"
            params.append(type)
        
        if status:
            sql += " AND status = ?"
            params.append(status)
        
        if platform:
            sql += " AND json_extract(data, '$.platform') = ?"
            params.append(platform)
        
        if start_date:
            sql += " AND created_at >= ?"
            params.append(start_date)
        
        sql += " ORDER BY created_at DESC LIMIT ?"
        params.append(limit)
        
        try:
            cursor = await self.conn.execute(sql, params)
            rows = await cursor.fetchall()
            
            tasks = []
            for row in rows:
                task = dict(row)
                # è§£æJSONå­—æ®µ
                if task.get('data'):
                    try:
                        task['data'] = json.loads(task['data'])
                    except:
                        pass
                if task.get('result'):
                    try:
                        task['result'] = json.loads(task['result'])
                    except:
                        pass
                tasks.append(task)
            
            logger.info(f"âœ… æŸ¥è¯¢ä»»åŠ¡æˆåŠŸ: {len(tasks)}ä¸ª")
            return tasks
        except Exception as e:
            logger.error(f"âŒ æŸ¥è¯¢ä»»åŠ¡å¤±è´¥: {e}")
            return []
    
    async def clear_tasks(
        self,
        type: Optional[str] = None,
        before_date: Optional[str] = None
    ):
        """
        æ¸…ç©ºä»»åŠ¡è®°å½•
        
        Args:
            type: ä»»åŠ¡ç±»å‹ï¼ˆå¯é€‰ï¼Œä¸æŒ‡å®šåˆ™æ¸…ç©ºæ‰€æœ‰ï¼‰
            before_date: æ—¥æœŸï¼ˆå¯é€‰ï¼Œæ¸…ç©ºæ­¤æ—¥æœŸä¹‹å‰çš„ä»»åŠ¡ï¼‰
        """
        sql = "DELETE FROM tasks WHERE 1=1"
        params = []
        
        if type:
            sql += " AND type = ?"
            params.append(type)
        
        if before_date:
            sql += " AND created_at < ?"
            params.append(before_date)
        
        try:
            cursor = await self.conn.execute(sql, params)
            await self.conn.commit()
            deleted_count = cursor.rowcount
            logger.info(f"âœ… æ¸…ç©ºä»»åŠ¡æˆåŠŸ: åˆ é™¤äº†{deleted_count}ä¸ªä»»åŠ¡")
        except Exception as e:
            logger.error(f"âŒ æ¸…ç©ºä»»åŠ¡å¤±è´¥: {e}")
    
    # ===== AIä½¿ç”¨ç»Ÿè®¡ =====
    
    async def log_ai_usage(
        self,
        provider: str,
        model: str,
        task_type: str,
        complexity: int,
        prompt_tokens: int = 0,
        completion_tokens: int = 0,
        latency: float = 0.0,
        success: bool = True,
        error: Optional[str] = None
    ):
        """
        è®°å½•AIä½¿ç”¨æƒ…å†µ
        
        Args:
            provider: AIæä¾›å•†
            model: æ¨¡å‹åç§°
            task_type: ä»»åŠ¡ç±»å‹
            complexity: ä»»åŠ¡å¤æ‚åº¦
            prompt_tokens: è¾“å…¥tokens
            completion_tokens: è¾“å‡ºtokens
            latency: å»¶è¿Ÿï¼ˆç§’ï¼‰
            success: æ˜¯å¦æˆåŠŸ
            error: é”™è¯¯ä¿¡æ¯
        """
        sql = """
        INSERT INTO ai_usage (
            provider, model, task_type, complexity,
            prompt_tokens, completion_tokens, total_tokens,
            latency, success, error
        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """
        
        total_tokens = prompt_tokens + completion_tokens
        
        try:
            await self.conn.execute(sql, (
                provider, model, task_type, complexity,
                prompt_tokens, completion_tokens, total_tokens,
                latency, 1 if success else 0, error
            ))
            await self.conn.commit()
        except Exception as e:
            logger.error(f"âŒ è®°å½•AIä½¿ç”¨å¤±è´¥: {e}")
    
    async def get_ai_stats(
        self,
        provider: Optional[str] = None,
        days: int = 7
    ) -> List[Dict[str, Any]]:
        """
        è·å–AIä½¿ç”¨ç»Ÿè®¡
        
        Args:
            provider: AIæä¾›å•†ï¼ˆå¯é€‰ï¼‰
            days: ç»Ÿè®¡å¤©æ•°
            
        Returns:
            ç»Ÿè®¡æ•°æ®
        """
        sql = """
        SELECT 
            provider,
            COUNT(*) as total_calls,
            SUM(prompt_tokens) as total_prompt_tokens,
            SUM(completion_tokens) as total_completion_tokens,
            SUM(total_tokens) as total_tokens,
            AVG(latency) as avg_latency,
            SUM(CASE WHEN success = 1 THEN 1 ELSE 0 END) as success_count
        FROM ai_usage
        WHERE created_at >= datetime('now', '-{} days')
        """.format(days)
        
        params = []
        if provider:
            sql += " AND provider = ?"
            params.append(provider)
        
        sql += " GROUP BY provider"
        
        try:
            cursor = await self.conn.execute(sql, params)
            rows = await cursor.fetchall()
            return [dict(row) for row in rows]
        except Exception as e:
            logger.error(f"âŒ æŸ¥è¯¢AIç»Ÿè®¡å¤±è´¥: {e}")
            return []
    
    async def get_ai_stats_summary(self) -> Dict[str, Any]:
        """
        è·å–AIä½¿ç”¨ç»Ÿè®¡æ‘˜è¦ï¼ˆç”¨äºä»ªè¡¨æ¿ï¼‰
        
        Returns:
            ç»Ÿè®¡æ‘˜è¦
        """
        sql = """
        SELECT 
            COUNT(*) as total_calls,
            SUM(CASE WHEN success = 1 THEN 1 ELSE 0 END) as success_count,
            AVG(latency) as avg_latency,
            SUM(total_tokens) as total_tokens
        FROM ai_usage
        """
        
        try:
            cursor = await self.conn.execute(sql)
            row = await cursor.fetchone()
            
            if row:
                result = dict(row)
                # è®¡ç®—æˆåŠŸç‡
                if result['total_calls'] > 0:
                    result['success_rate'] = (result['success_count'] / result['total_calls']) * 100
                else:
                    result['success_rate'] = 0
                return result
            else:
                return {
                    'total_calls': 0,
                    'success_count': 0,
                    'avg_latency': 0,
                    'total_tokens': 0,
                    'success_rate': 0
                }
        except Exception as e:
            logger.error(f"âŒ æŸ¥è¯¢AIç»Ÿè®¡æ‘˜è¦å¤±è´¥: {e}")
            return {
                'total_calls': 0,
                'success_count': 0,
                'avg_latency': 0,
                'total_tokens': 0,
                'success_rate': 0
            }
    
    async def get_ai_calls(
        self,
        start_time: str,
        end_time: str,
        provider: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """
        è·å–æŒ‡å®šæ—¶é—´èŒƒå›´å†…çš„AIè°ƒç”¨è®°å½•ï¼ˆç”¨äºå›¾è¡¨ï¼‰
        
        Args:
            start_time: å¼€å§‹æ—¶é—´ï¼ˆISOæ ¼å¼ï¼‰
            end_time: ç»“æŸæ—¶é—´ï¼ˆISOæ ¼å¼ï¼‰
            provider: AIæä¾›å•†ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            AIè°ƒç”¨è®°å½•åˆ—è¡¨
        """
        if provider:
            sql = """
            SELECT 
                id, provider, model, task_type, complexity,
                prompt_tokens, completion_tokens, total_tokens,
                latency, success, error, created_at
            FROM ai_usage
            WHERE created_at >= ? AND created_at <= ? AND provider = ?
            ORDER BY created_at ASC
            """
            params = (start_time, end_time, provider)
        else:
            sql = """
            SELECT 
                id, provider, model, task_type, complexity,
                prompt_tokens, completion_tokens, total_tokens,
                latency, success, error, created_at
            FROM ai_usage
            WHERE created_at >= ? AND created_at <= ?
            ORDER BY created_at ASC
            """
            params = (start_time, end_time)
        
        try:
            cursor = await self.conn.execute(sql, params)
            rows = await cursor.fetchall()
            
            calls = []
            for row in rows:
                call = dict(row)
                # å°†successå­—æ®µä»0/1è½¬æ¢ä¸ºå¸ƒå°”å€¼
                call['success'] = bool(call['success'])
                calls.append(call)
            
            return calls
        except Exception as e:
            logger.error(f"âŒ æŸ¥è¯¢AIè°ƒç”¨è®°å½•å¤±è´¥: {e}")
            return []
    
    # ===== é…ç½®ç®¡ç† =====
    
    async def get_config(self, key: str) -> Optional[str]:
        """
        è·å–é…ç½®å€¼
        
        Args:
            key: é…ç½®é”®
            
        Returns:
            é…ç½®å€¼
        """
        sql = "SELECT value FROM config WHERE key = ?"
        
        try:
            cursor = await self.conn.execute(sql, (key,))
            row = await cursor.fetchone()
            return row["value"] if row else None
        except Exception as e:
            logger.error(f"âŒ è·å–é…ç½®å¤±è´¥: {e}")
            return None
    
    async def set_config(self, key: str, value: str):
        """
        è®¾ç½®é…ç½®å€¼
        
        Args:
            key: é…ç½®é”®
            value: é…ç½®å€¼
        """
        sql = """
        INSERT OR REPLACE INTO config (key, value, updated_at)
        VALUES (?, ?, CURRENT_TIMESTAMP)
        """
        
        try:
            await self.conn.execute(sql, (key, value))
            await self.conn.commit()
        except Exception as e:
            logger.error(f"âŒ è®¾ç½®é…ç½®å¤±è´¥: {e}")


# ===== æµ‹è¯•å‡½æ•° =====

async def test_database():
    """æµ‹è¯•æ•°æ®åº“åŠŸèƒ½"""
    
    print("\n" + "="*60)
    print("ğŸ§ª æµ‹è¯•æ•°æ®åº“ç®¡ç†å™¨")
    print("="*60)
    
    # åˆ›å»ºæ•°æ®åº“å®ä¾‹
    db = Database("data/database.db")
    
    try:
        # 1. è¿æ¥æ•°æ®åº“
        print("\n1ï¸âƒ£ è¿æ¥æ•°æ®åº“...")
        await db.connect()
        
        # 2. æ’å…¥æµ‹è¯•å•†å“
        print("\n2ï¸âƒ£ æ’å…¥æµ‹è¯•å•†å“...")
        test_products = [
            {
                "title": "æµ‹è¯•å•†å“1 - iPhone 13",
                "price": 3999,
                "category": "æ•°ç äº§å“",
                "description": "æµ‹è¯•æè¿°",
                "images": ["image1.jpg"],
                "import_time": datetime.now().isoformat(),
                "row_number": 1
            },
            {
                "title": "æµ‹è¯•å•†å“2 - AirPods Pro",
                "price": 1599,
                "category": "æ•°ç é…ä»¶",
                "description": "æµ‹è¯•æè¿°",
                "images": ["image2.jpg"],
                "import_time": datetime.now().isoformat(),
                "row_number": 2
            }
        ]
        
        count = await db.insert_products(test_products)
        print(f"æˆåŠŸæ’å…¥ {count} ä¸ªå•†å“")
        
        # 3. æŸ¥è¯¢å•†å“
        print("\n3ï¸âƒ£ æŸ¥è¯¢å•†å“...")
        products = await db.get_products(status="å¾…å‘å¸ƒ", limit=10)
        print(f"æŸ¥è¯¢åˆ° {len(products)} ä¸ªå•†å“")
        for p in products:
            print(f"  - {p['title']} (Â¥{p['price']})")
        
        # 4. è®°å½•AIä½¿ç”¨
        print("\n4ï¸âƒ£ è®°å½•AIä½¿ç”¨...")
        await db.log_ai_usage(
            provider="ollama",
            model="deepseek-r1:1.5b",
            task_type="title_optimization",
            complexity=1,
            prompt_tokens=50,
            completion_tokens=30,
            latency=2.5,
            success=True
        )
        print("AIä½¿ç”¨è®°å½•æˆåŠŸ")
        
        # 5. æŸ¥çœ‹AIç»Ÿè®¡
        print("\n5ï¸âƒ£ æŸ¥çœ‹AIç»Ÿè®¡...")
        stats = await db.get_ai_stats()
        for stat in stats:
            print(f"  - {stat['provider']}: {stat['total_calls']} æ¬¡è°ƒç”¨")
        
        print("\n" + "="*60)
        print("âœ… æ•°æ®åº“æµ‹è¯•å®Œæˆï¼")
        print("="*60 + "\n")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        # å…³é—­è¿æ¥
        await db.close()


if __name__ == "__main__":
    import asyncio
    
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # è¿è¡Œæµ‹è¯•
    asyncio.run(test_database())

